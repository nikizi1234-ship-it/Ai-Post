import os
import logging
import feedparser
import requests
from datetime import datetime
from telegram import Bot, InputMediaPhoto
from telegram.error import TelegramError
from bs4 import BeautifulSoup
import json
import asyncio
import aiohttp
from typing import Optional, List, Tuple
import traceback
import sys

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Railway
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHANNEL_ID = os.environ.get('CHANNEL_ID')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not BOT_TOKEN:
    logger.error("BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    sys.exit(1)
if not CHANNEL_ID:
    logger.error("CHANNEL_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    sys.exit(1)

class ITNewsBot:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞"""
        self.bot = Bot(token=BOT_TOKEN)
        self.channel_id = CHANNEL_ID
        
        # –î–ª—è Railway –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        self.data_dir = os.path.join(os.getcwd(), 'data')
        os.makedirs(self.data_dir, exist_ok=True)
        self.sent_articles_file = os.path.join(self.data_dir, 'sent_articles.json')
        
        self.sent_articles = self.load_sent_articles()
        
        # RSS-–ª–µ–Ω—Ç—ã IT-–Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        self.rss_feeds = [
            "https://habr.com/ru/rss/hubs/all/",
            "https://www.opennet.ru/opennews/opennews_all.rss",
            "https://news.ycombinator.com/rss",
            "https://www.reddit.com/r/programming/.rss",
            "https://dev.to/feed",
            "https://techcrunch.com/feed/",
            "https://feeds.feedburner.com/TheHackersNews",
        ]
        
        # User-Agent –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # –°–µ—Å—Å–∏—è –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self.session = None
        
    async def init_session(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è HTTP-—Å–µ—Å—Å–∏–∏"""
        if not self.session:
            self.session = aiohttp.ClientSession(headers=self.headers)
    
    def load_sent_articles(self) -> set:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π"""
        try:
            if os.path.exists(self.sent_articles_file):
                with open(self.sent_articles_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content:
                        data = json.loads(content)
                        return set(data.get('articles', []))
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if os.path.exists(self.sent_articles_file):
                backup_file = self.sent_articles_file + '.bak'
                os.rename(self.sent_articles_file, backup_file)
                logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Ñ–∞–π–ª–∞: {backup_file}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {e}")
            logger.error(traceback.format_exc())
        
        return set()
    
    def save_sent_article(self, article_id: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ID –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏"""
        try:
            self.sent_articles.add(article_id)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å—Ç–∞—Ç–µ–π)
            if len(self.sent_articles) > 1000:
                self.sent_articles = set(list(self.sent_articles)[-1000:])
            
            data = {'articles': list(self.sent_articles)}
            with open(self.sent_articles_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å—Ç–∞—Ç—å—è ID: {article_id}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
            logger.error(traceback.format_exc())
    
    async def fetch_feed(self, rss_url: str) -> Tuple[List, str]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ RSS-–ª–µ–Ω—Ç—ã"""
        try:
            await self.init_session()
            async with self.session.get(rss_url, timeout=10) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)
                    return feed.entries[:3], feed.feed.get('title', 'Unknown Source')
                else:
                    logger.warning(f"–û—à–∏–±–∫–∞ HTTP {response.status} –¥–ª—è {rss_url}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è RSS {rss_url}: {e}")
        
        return [], 'Unknown Source'
    
    async def extract_image_url(self, entry) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∑–∞–ø–∏—Å–∏"""
        image_url = None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
        try:
            # –í –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–µ
            if hasattr(entry, 'media_content') and entry.media_content:
                for media in entry.media_content:
                    if media.get('type', '').startswith('image/'):
                        image_url = media.get('url')
                        if image_url:
                            break
            
            # –í —Å—Å—ã–ª–∫–∞—Ö
            if not image_url and hasattr(entry, 'links'):
                for link in entry.links:
                    if getattr(link, 'type', '').startswith('image/'):
                        image_url = getattr(link, 'href', None)
                        if image_url:
                            break
            
            # –í –∫–æ–Ω—Ç–µ–Ω—Ç–µ (HTML)
            if not image_url and hasattr(entry, 'content'):
                for content in entry.content:
                    soup = BeautifulSoup(content.value, 'html.parser')
                    img_tags = soup.find_all('img')
                    for img in img_tags:
                        src = img.get('src')
                        if src and (src.startswith('http://') or src.startswith('https://')):
                            image_url = src
                            break
                    if image_url:
                        break
            
            # –í –æ–ø–∏—Å–∞–Ω–∏–∏
            if not image_url and hasattr(entry, 'description'):
                soup = BeautifulSoup(entry.description, 'html.parser')
                img_tags = soup.find_all('img')
                for img in img_tags:
                    src = img.get('src')
                    if src and (src.startswith('http://') or src.startswith('https://')):
                        image_url = src
                        break
        
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        
        # –ó–∞–≥–ª—É—à–∫–∞, –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        if not image_url:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ IT-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            image_urls = [
                "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400&fit=crop",
                "https://images.unsplash.com/photo-1518709268805-4e9042af2176?w=800&h=400&fit=crop",
                "https://images.unsplash.com/photo-1457305237443-44c3d5a30b89?w=800&h=400&fit=crop",
            ]
            import random
            image_url = random.choice(image_urls)
        
        return image_url
    
    async def fetch_news_from_rss(self) -> List[Tuple[dict, str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS-–ª–µ–Ω—Ç"""
        all_articles = []
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ RSS-–∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [self.fetch_feed(rss_url) for rss_url in self.rss_feeds]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for idx, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"–û—à–∏–±–∫–∞ –≤ RSS –∑–∞–¥–∞—á–µ {self.rss_feeds[idx]}: {result}")
                continue
            
            entries, source = result
            
            for entry in entries:
                try:
                    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —Å—Ç–∞—Ç—å–∏
                    article_id = f"{self.rss_feeds[idx]}_{entry.get('id', entry.link)}"
                    
                    if article_id in self.sent_articles:
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image_url = await self.extract_image_url(entry)
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
                    article = {
                        'title': entry.title[:200] + "..." if len(entry.title) > 200 else entry.title,
                        'description': entry.get('summary', entry.get('description', ''))[:300] + "..."
                                    if len(entry.get('summary', '')) > 300 
                                    else entry.get('summary', entry.get('description', '')),
                        'url': entry.link,
                        'image_url': image_url,
                        'published': entry.get('published', entry.get('updated', datetime.now().isoformat())),
                        'source': source,
                        'content': entry.get('content', [{}])[0].get('value', '')[:500] + "..."
                                if entry.get('content') 
                                else entry.get('summary', entry.get('description', ''))[:500] + "..."
                    }
                    
                    all_articles.append((article, article_id))
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏: {e}")
                    continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏ –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        try:
            all_articles.sort(key=lambda x: x[0].get('published', ''), reverse=True)
        except:
            pass
        
        return all_articles
    
    def generate_hashtags(self, title: str, source: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à—Ç–µ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        hashtags = []
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è IT-—Ç–µ–º–∞—Ç–∏–∫–∏
        it_keywords = {
            'python': ['Python', '–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'],
            'javascript': ['JavaScript', 'JS', 'Web'],
            'java': ['Java'],
            'c#': ['CSharp', 'DotNet'],
            'php': ['PHP'],
            'ruby': ['Ruby'],
            'go': ['Go', 'Golang'],
            'rust': ['Rust'],
            'ai': ['AI', '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç', '–ú–∞—à–∏–Ω–Ω–æ–µ–û–±—É—á–µ–Ω–∏–µ'],
            'machine learning': ['MachineLearning', 'ML'],
            'deep learning': ['DeepLearning', '–ù–µ–π—Ä–æ–Ω–Ω—ã–µ–°–µ—Ç–∏'],
            'cybersecurity': ['–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', 'Security'],
            'blockchain': ['Blockchain', '–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã'],
            'web': ['WebDevelopment', '–í–µ–±–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞'],
            'mobile': ['Mobile', '–ú–æ–±–∏–ª—å–Ω–∞—è–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞'],
            'devops': ['DevOps'],
            'cloud': ['Cloud', '–û–±–ª–∞—á–Ω—ã–µ–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'],
            'database': ['–ë–∞–∑—ã–î–∞–Ω–Ω—ã—Ö', 'SQL', 'NoSQL'],
            'linux': ['Linux'],
            'windows': ['Windows'],
            'ios': ['iOS'],
            'android': ['Android'],
            'startup': ['–°—Ç–∞—Ä—Ç–∞–ø—ã', 'Startup'],
        }
        
        title_lower = title.lower()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        for keyword, tags in it_keywords.items():
            if keyword in title_lower:
                hashtags.extend(tags)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_tags = {
            'habr': ['Habr', '–•–∞–±—Ä'],
            'hacker news': ['HackerNews'],
            'reddit': ['Reddit'],
            'dev.to': ['DevCommunity'],
            'techcrunch': ['TechCrunch'],
            'opennet': ['OpenNet'],
        }
        
        for source_key, tags in source_tags.items():
            if source_key in source.lower():
                hashtags.extend(tags)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Ç–µ–≥–∏
        general_tags = ['IT', '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'IT–ù–æ–≤–æ—Å—Ç–∏', '–ù–æ–≤–æ—Å—Ç–∏–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–π', '–ü—Ä–æ–≥—Ä–µ—Å—Å']
        hashtags.extend(general_tags)
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        hashtags = list(dict.fromkeys(hashtags))[:8]
        
        return ' '.join(['#' + tag.replace(' ', '').replace('-', '') for tag in hashtags])
    
    def format_published_date(self, date_str: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
            date_formats = [
                '%a, %d %b %Y %H:%M:%S %Z',
                '%a, %d %b %Y %H:%M:%S %z',
                '%Y-%m-%dT%H:%M:%SZ',
                '%Y-%m-%d %H:%M:%S',
                '%d.%m.%Y %H:%M',
            ]
            
            for fmt in date_formats:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.strftime('%d.%m.%Y %H:%M')
                except:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–æ—à–µ–ª, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É
            return date_str[:16]
        except:
            return "–î–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
    
    def create_post_content(self, article: dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        try:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
            date_str = self.format_published_date(article.get('published', ''))
            
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
            reasoning = article.get('content', article.get('description', ''))
            if len(reasoning) > 800:
                reasoning = reasoning[:800] + "..."
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å—Ç
            post = f"""
üì∞ *{article['title']}*

*–ò—Å—Ç–æ—á–Ω–∏–∫:* {article['source']}
*–î–∞—Ç–∞:* {date_str}

üí≠ *–†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è:*
{reasoning}

üìñ [–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({article['url']})

{self.generate_hashtags(article['title'], article['source'])}
"""
            
            return post.strip()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Å—Ç–∞: {e}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏"
    
    async def download_image(self, image_url: str) -> Optional[bytes]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            await self.init_session()
            async with self.session.get(image_url, timeout=15) as response:
                if response.status == 200:
                    return await response.read()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_url}: {e}")
        return None
    
    async def send_news_to_channel(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∫–∞–Ω–∞–ª"""
        try:
            logger.info("–ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π...")
            articles = await self.fetch_news_from_rss()
            
            if not articles:
                logger.warning("–ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é —Å—Ç–∞—Ç—å—é
            article, article_id = articles[0]
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {article['title'][:50]}...")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Å—Ç–∞
            post_content = self.create_post_content(article)
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_data = await self.download_image(article['image_url'])
            
            if image_data:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                temp_image = os.path.join(self.data_dir, 'temp_image.jpg')
                with open(temp_image, 'wb') as f:
                    f.write(image_data)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
                with open(temp_image, 'rb') as photo:
                    await self.bot.send_photo(
                        chat_id=self.channel_id,
                        photo=photo,
                        caption=post_content,
                        parse_mode='Markdown'
                    )
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                os.remove(temp_image)
            else:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                await self.bot.send_message(
                    chat_id=self.channel_id,
                    text=post_content,
                    parse_mode='Markdown',
                    disable_web_page_preview=False
                )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
            self.save_sent_article(article_id)
            logger.info(f"–°—Ç–∞—Ç—å—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {article['title'][:50]}...")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            logger.error(traceback.format_exc())
            return False
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.session:
            await self.session.close()
    
    async def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±–æ—Ç–∞"""
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
        
        try:
            while True:
                await self.send_news_to_channel()
                
                # –ñ–¥–µ–º 6 —á–∞—Å–æ–≤ (21600 —Å–µ–∫—É–Ω–¥)
                logger.info("–û–∂–∏–¥–∞–Ω–∏–µ 6 —á–∞—Å–æ–≤ –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –æ—Ç–ø—Ä–∞–≤–∫–∏...")
                await asyncio.sleep(21600)
                
        except asyncio.CancelledError:
            logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            logger.error(traceback.format_exc())
        finally:
            await self.cleanup()

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    bot = ITNewsBot()
    try:
        await bot.run()
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        await bot.cleanup()

if __name__ == '__main__':
    asyncio.run(main())
